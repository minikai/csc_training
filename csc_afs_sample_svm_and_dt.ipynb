{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "manifest = {\n",
    "    'memory': 2048,\n",
    "    'disk_quota': 2048,\n",
    "    'buildpack': 'python_buildpack',\n",
    "    'type': 'APP'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***IMPROTANT***\n",
    "About the above cell, it will tansform the program in the notebook into an \"APP\" for AFS.    \n",
    "Please be sure that the \"manifest\" is the first word of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo    \n",
    "## Training Support Vector Machine (svm) and Decision Tree (dt) model      \n",
    "---\n",
    "In the demo, there five parts are included as follows: \n",
    "1. InfluxDB Configurations  \n",
    "2. Data preprocessing  \n",
    "3. Training SVM model\n",
    "4. Training Decision Tree model  \n",
    "5. AFS SDK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. InfluxDB Configurations    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input the information of influxDB\n",
    "from influxdb import DataFrameClient\n",
    "# serviceHost\n",
    "host = ''\n",
    "port = \n",
    "# username\n",
    "user = ''\n",
    "# password\n",
    "password = ''\n",
    "# database\n",
    "dbname = ''\n",
    "\n",
    "# Temporarily avoid line protocol time conversion issues #412, #426, #431.\n",
    "protocol = 'json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataFrameClient transfrom data from DB to dataframe\n",
    "client = DataFrameClient(host, port, user, password, dbname)\n",
    "result = client.query('show measurements')\n",
    "print(\"Result: {0}\".format(result))\n",
    "\n",
    "# measurements\n",
    "measurements = ''\n",
    "\n",
    "# Read sample_data\n",
    "sample_data = client.query('select * from ' + measurements)\n",
    "data = sample_data[measurements]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "data['EVENT'] = np.where(data['TEMPERATURE_OUTPUT']>=98, '1', '0')\n",
    "col = [ 'STATUS_FAN',\n",
    "        'VOLTAGE_INPUT',\n",
    "        'PRESSURE_OUTPUT',\n",
    "        'KW_FAN',       \n",
    "        'KW_EQUIPMENT',      \n",
    "        'KW_SUMMARY'          \n",
    "    ]\n",
    "col_2 = [ 'STATUS_FAN',\n",
    "          'VOLTAGE_INPUT',\n",
    "          'PRESSURE_OUTPUT',\n",
    "          'KW_FAN',       \n",
    "          'KW_EQUIPMENT',      \n",
    "          'KW_SUMMARY',\n",
    "          'EVENT'\n",
    "    ]\n",
    "\n",
    "data_1 = data[col]\n",
    "data_2 = data[col_2]\n",
    "\n",
    "data_10 = np.concatenate((data_1,data_1,data_1,data_1,data_1,\n",
    "                          data_1,data_1,data_1,data_1,data_2),axis=1)\n",
    "\n",
    "# shift to make time window\n",
    "data_10 = pd.DataFrame(data_10)\n",
    "\n",
    "for i in range(10):\n",
    "    data_10.iloc[:,0+6*i:6+6*i] = data_10.iloc[:,0+6*i:6+6*i].shift(periods=9-i)\n",
    "\n",
    "data_10.iloc[:,0:60] = data_10.iloc[:,0:60].shift(periods=12)\n",
    "data = data_10.dropna(axis=0)\n",
    "\n",
    "# split data into train and test sets\n",
    "X = data.iloc[:,0:60]\n",
    "Y = data.iloc[:,60]\n",
    "seed = 100\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training SVM model    \n",
    "#### Save the model as \"svm_model_csc.pkl\" file after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training SVM model\n",
    "svm_clf = svm.SVC(kernel='rbf', C=1.0, probability=True)\n",
    "svm_clf = svm_clf.fit(X_train, y_train) \n",
    "\n",
    "# evaluate predictions\n",
    "y_pre = svm_clf.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, y_pre)\n",
    "print(\"SVM Accuracy: %.2f%%\" % (svm_accuracy * 100.0))\n",
    "\n",
    "y_prob = svm_clf.predict_proba(X_test)\n",
    "svm_loss = log_loss(y_test, y_prob)\n",
    "print(\"SVM loss: %.2f%%\" % (svm_loss*100.0))\n",
    "\n",
    "# save model\n",
    "joblib.dump(svm_clf, 'svm_model_csc.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Decision Tree model    \n",
    "#### Save the model as \"dt_model_csc.pkl\" file after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Decision Tree\n",
    "dt_clf = tree.DecisionTreeClassifier()\n",
    "dt_clf = dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate predictions\n",
    "y_pre = dt_clf.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pre)\n",
    "print(\"DT Accuracy: %.2f%%\" % (dt_accuracy * 100.0))\n",
    "\n",
    "y_prob = dt_clf.predict_proba(X_test)\n",
    "dt_loss = log_loss(y_test, y_prob)\n",
    "print(\"DT loss: %.2f%%\" % (dt_loss*100.0))\n",
    "\n",
    "# save model to pkl\n",
    "joblib.dump(dt_clf, 'dt_model_csc.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AFS SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AFS SDK for SVM\n",
    "from afs.client import afs\n",
    "client = afs()\n",
    "client.models.upload_model('svm_model_csc.pkl', \n",
    "                           accuracy=svm_accuracy, \n",
    "                           loss=svm_loss, \n",
    "                           tags=dict(machine='machine01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AFS SDK for Decision Tree\n",
    "from afs.client import afs\n",
    "client = afs()\n",
    "client.models.upload_model('dt_model_csc.pkl', \n",
    "                           accuracy=dt_accuracy, \n",
    "                           loss=dt_loss, \n",
    "                           tags=dict(machine='machine01'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
